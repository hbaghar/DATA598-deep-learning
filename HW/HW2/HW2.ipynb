{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Multiple Layer Perceptron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Performance vs. Width\n",
    "\n",
    "In this exercise, we will experiment with the number of hidden units in a multilayer perceptron (MLP) with a single hidden layer. The number of hidden units is also referred to the width of the hidden layer.\n",
    "\n",
    "Here are the details:\n",
    "- The setup is identical to the demo/lab and you may reuse that code. Take the FashionMNIST dataset and randomly subsample 12% of its training set to work with. As a test set, we will use the full test set of FashionMNIST.\n",
    "- Define a MLP with one hidden layer of width h = 16. Find the divergent learning rate η∗ for this model and use a fixed learning rate of η∗/2, as we discussed in class.\n",
    "- Train the model for 120 passes over the data.\n",
    "- Repeat this procedure for widths h = 8, 32, 128, 512 with the same learning rate η∗/2 as above (i.e., you do not need to find the divergent learning rate of each model for this exercise).\n",
    "\n",
    "\n",
    "The deliverables for this exercise are:\n",
    "1. Make 4 plots, one each for the train loss, train accuracy, test loss and test accuracy over the course of training (i.e., the metric on the y-axis and number of effective passes on the x-axis). Plot all 4 lines, one for each value of h on the same plot.\n",
    "2. When the training accuracy is 100%, the model is said to interpolate the training data. What is the smallest width at which we observe perfect interpolation of the training data?\n",
    "3. As we vary the width of the network, at which training epoch do we observe perfect interpolation of the data? That is, make a plot with h on the x-axis and number of passes over the data required for interpolation on the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.nn.functional import cross_entropy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "# Fix the random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the MNIST dataset\n",
    "\n",
    "We load the MNIST dataset and set up some helper functions to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([7200, 28, 28])\n",
      "n_train: 7200, n_test: 10000\n",
      "Image size: torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# download dataset (~117M in size)\n",
    "train_dataset = FashionMNIST('../../data', train=True, download=False)\n",
    "X_train = train_dataset.data # torch tensor of type uint8 of shape (n, 28, 28)\n",
    "y_train = train_dataset.targets.long() # torch tensor of type Long of shape (n,)\n",
    "test_dataset = FashionMNIST('../../data', train=False, download=False)\n",
    "X_test = test_dataset.data\n",
    "y_test = test_dataset.targets.long()\n",
    "\n",
    "# choose a subsample of 10% of the data:\n",
    "idxs_train = torch.from_numpy(\n",
    "    np.random.choice(X_train.shape[0], replace=False, size=int(X_train.shape[0]*0.12)))\n",
    "X_train, y_train = X_train[idxs_train], y_train[idxs_train]\n",
    "idxs_test = torch.from_numpy(\n",
    "    np.random.choice(X_test.shape[0], replace=False, size=X_test.shape[0]))\n",
    "X_test, y_test = X_test[idxs_test], y_test[idxs_test]\n",
    "\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'n_train: {X_train.shape[0]}, n_test: {X_test.shape[0]}')\n",
    "print(f'Image size: {X_train.shape[1:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Row of Pixels: tensor([ 0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  0, 69, 98,  0, 95, 37,  0,\n",
      "         0,  1,  1,  0,  0,  0,  0,  0,  0,  0], dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, idx in enumerate(np.random.choice(X_train.shape[0], 5)):\n",
    "    ax[i].imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)\n",
    "    ax[i].set_title(f'Label = {y_train[idx]}', fontsize=20)\n",
    "# Each number represents the grayscale intensity [0, 255]\n",
    "print(\"One Row of Pixels:\", X_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us normalize the data and define some utility functions. We start by flattening the $28 \\times 28$ image into a vector of size $784$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: torch.Size([7200, 28, 28])\n",
      "Flatten Shape: torch.Size([7200, 784])\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Shape:\", X_train.shape)\n",
    "X_train = X_train.float()  # convert to float32. Shape: (n, 28, 28)\n",
    "X_train = X_train.view(-1, 784)  # Shape: (n, 784)\n",
    "print(\"Flatten Shape:\", X_train.shape)\n",
    "mean, std = X_train.mean(axis=0), X_train.std(axis=0)  # Shape: (784,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes:  10\n"
     ]
    }
   ],
   "source": [
    "# Normalize dataset: pixel values lie between 0 and 255\n",
    "# Normalize them so the pixelwise mean is zero and standard deviation is 1\n",
    "# Normalize: add a small number to avoid divide by zero\n",
    "X_train = (X_train - mean[None, :]) / (std[None, :] + 1e-6) # Shape: (n, 784)\n",
    "\n",
    "X_test = X_test.float()  # Shape: (n', 28, 28)\n",
    "X_test = X_test.view(-1, 784)  # Shape: (n', 784)\n",
    "X_test = (X_test - mean[None, :]) / (std[None, :] + 1e-6)  # Shape: (n', 784)\n",
    "\n",
    "n_class = np.unique(y_train).shape[0]  # We have K=10 classes numbered (0, 1, ..., 9)\n",
    "print(\"Number of Classes: \", n_class)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Setup Code for Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions to compute the objective and the accuracy\n",
    "\n",
    "def mlp(X, ws, bs):\n",
    "    hidden = X # Shape: (n, d_0)\n",
    "    for w, b in zip(ws[:-1], bs[:-1]):\n",
    "        # hidden = relu(W_(r<j)x + b_(r<j))\n",
    "        hidden = torch.matmul(hidden, w) + b[None, :]  # Shape: (n, d_{j-1}) * (d_{j-1}, d_j) = (n, d_j)\n",
    "        hidden = torch.nn.functional.relu(hidden)\n",
    "    # return W_j(hidden)+ b_j\n",
    "    return torch.matmul(hidden, ws[-1]) + bs[-1][None, :]\n",
    "\n",
    "def compute_objective(ws, bs, X, y, reg_param):\n",
    "    \"\"\" Compute the multinomial logistic loss. \n",
    "        ws is a list of tensors of consistent shapes,\n",
    "        X of shape (n, d) and y of shape (n,)\n",
    "    \"\"\"\n",
    "    score = mlp(X, ws, bs)  # Shape: (n, K)\n",
    "    # PyTorch's function cross_entropy computes the multinomial logistic loss\n",
    "    # Adding L2 penalization\n",
    "    return (\n",
    "        cross_entropy(input=score, target=y, reduction='mean') \n",
    "        + 0.5 * reg_param * sum([torch.norm(w)**2 for w in ws])\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(ws, bs, X, y):\n",
    "    \"\"\" Compute the classification accuracy\n",
    "        ws is a list of tensors of consistent shapes \n",
    "        X of shape (n, d) and y of shape (n,)\n",
    "    \"\"\"\n",
    "    score = mlp(X, ws, bs)  # shape: (n, K`)\n",
    "    predictions = torch.argmax(score, axis=1)  # class with highest score is predicted\n",
    "    return (predictions == y).sum() * 1.0 / y.shape[0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_logs(ws, bs, reg_param, verbose=False):\n",
    "    train_loss = compute_objective(ws, bs, X_train, y_train, reg_param)\n",
    "    test_loss = compute_objective(ws, bs, X_test, y_test, reg_param)\n",
    "    train_accuracy = compute_accuracy(ws, bs, X_train, y_train)\n",
    "    test_accuracy = compute_accuracy(ws, bs, X_test, y_test)\n",
    "    if verbose:\n",
    "        print(('Train Loss = {:.3f}, Train Accuracy = {:.3f}, ' + \n",
    "               'Test Loss = {:.3f}, Test Accuracy = {:.3f}').format(\n",
    "                train_loss.item(), train_accuracy.item(), \n",
    "                test_loss.item(), test_accuracy.item())\n",
    "    )\n",
    "    return (train_loss, train_accuracy, test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us again write the analogous function to make a pass of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_one_pass(ws, bs, X, y, reg_param, learning_rate, verbose=False):\n",
    "    num_examples = X.shape[0]\n",
    "    average_loss = 0.0\n",
    "    for i in range(num_examples):\n",
    "        idx = np.random.choice(X.shape[0])\n",
    "        # compute the objective. \n",
    "        # Note: This function requires X to be of shape (n,d). In this case, n=1 \n",
    "        objective = compute_objective(ws, bs, X[idx:idx+1], y[idx:idx+1], reg_param)\n",
    "  \n",
    "        average_loss = 0.99 * average_loss + 0.01 * objective.item()\n",
    "        if verbose and (i+1) % 100 == 0:\n",
    "            print(average_loss)\n",
    "        \n",
    "        # compute the gradient using automatic differentiation\n",
    "        all_parameters = [*ws, *bs]\n",
    "        gradients = torch.autograd.grad(outputs=objective, inputs=all_parameters)\n",
    "        \n",
    "        # perform SGD update. IMPORTANT: Make the update inplace!\n",
    "        with torch.no_grad():\n",
    "            for (var, g) in zip(all_parameters, gradients):\n",
    "                var -= learning_rate * g\n",
    "    return ws, bs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Finding divergent learning rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we change the learning rate, there are two extreme regimes:\n",
    "\n",
    "- If the learning rate is too large, the weights diverge to infinity (that is, the coordinates of $w$ increase without bound to $\\pm\\infty$).\n",
    "- On the other hand, if the learning rate is too small, the optimization takes a very large number of iterations to converge (the per iteration cost is quite high for complex model). \n",
    "\n",
    "In order to balance these two, we look for the *divergent learning rate*. We say $\\eta^\\star$ is the divergent learning rate if SGD with a learning rate of $2\\eta^\\star$ diverges, but SGD with a learning rate of $\\eta^\\star$ does not. \n",
    "\n",
    "**Divergent LR Heuristic**: A good starting learning rate is $\\eta^\\star/2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the divergent learning rate. Edit the code below to change the learning rate. \n",
    "\n",
    "*Hint 1*: Try different orders of magnitude. For instance, start with 1e-2. If it diverges, try 1e-6, if not, try 10.0. Once we establish a lower and upper bound on it, finding the divergent learning rate comes down to a binary search (on a logarithmic scale). \n",
    "\n",
    "*Hint 2*: A common strategy is to search in powers of 10 (as in hint 1), and then narrow the search down in powers of 2. For instance, if we end up with 1e-3 as an estimate of the divergent learning from hint 1, try out 2e-3 and 4e-3 as well in order to refine the estimate of the divergent learning rate. \n",
    "\n",
    "**Note**: the divergent learning rate is a heuristic which gives the right ballpark figure of the learning rate. \n",
    "A learning rate that satisfies the heuristic might still result in the loss diverging, in which case we would have redo the process with half that learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.083, Test Loss = 2.303, Test Accuracy = 0.081\n",
      "1.4602855443442406\n",
      "1.9914672689465307\n",
      "2.190249587064884\n",
      "2.2543304791256853\n",
      "2.2815595363116805\n",
      "2.268722927783318\n",
      "2.0477432164231826\n",
      "1.8871491136353395\n",
      "1.7258144618411517\n",
      "1.4211583909763912\n",
      "1.3216764810278707\n",
      "1.1953618297129833\n",
      "1.1780433892492583\n",
      "1.2165141571048008\n",
      "1.2429606947069363\n",
      "1.0701868445613216\n",
      "0.9928330581930458\n",
      "1.0052379314686888\n",
      "0.9065293018627636\n",
      "0.9522599300567698\n",
      "0.9371706918958739\n",
      "0.8844464047107415\n",
      "0.8186165748104676\n",
      "0.8131910642676007\n",
      "0.8910933124048723\n",
      "0.8200543628503526\n",
      "0.9334232478382668\n",
      "0.7642089777075686\n",
      "0.650189653181696\n",
      "0.6489457886698646\n",
      "0.7759334043294583\n",
      "0.7804062333521101\n",
      "0.9015311581392766\n",
      "0.8129594256155092\n",
      "0.8368987538751619\n",
      "0.6919538223494238\n",
      "0.7223510477588927\n",
      "0.6676960985486641\n",
      "0.6605225315076836\n",
      "0.7412658207629533\n",
      "0.8203499294539082\n",
      "0.7624322808985978\n",
      "0.7810924214862878\n",
      "0.6893410518388317\n",
      "0.6973349653142915\n",
      "0.6238743659006077\n",
      "0.6435956339308255\n",
      "0.633609955069441\n",
      "0.8002047081346144\n",
      "0.755556123095075\n",
      "0.5969362112088401\n",
      "0.5658492787839247\n",
      "0.5909313073362173\n",
      "0.6712739861581054\n",
      "0.7109988064693719\n",
      "0.6685898460763496\n",
      "0.7099173359528407\n",
      "0.639970397406344\n",
      "0.5937950771711328\n",
      "0.5130658735496751\n",
      "0.4953790882396444\n",
      "0.66833910657603\n",
      "0.7533657263543933\n",
      "0.5234708547870955\n",
      "0.6130652360085569\n",
      "0.6659628303003039\n",
      "0.6722318569255501\n",
      "0.6409586049258713\n",
      "0.6373700019075005\n",
      "0.5688513994205417\n",
      "0.7498187797506184\n",
      "0.642787887548577\n",
      "Train Loss = 0.671, Train Accuracy = 0.733, Test Loss = 0.771, Test Accuracy = 0.711\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(1)\n",
    "reg_param = 0.0\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "hidden_size = 16 # Specifying hidden layer size as required by the assignment\n",
    "ws = [1e-6 * torch.randn(784, hidden_size, requires_grad=True),\n",
    "      1e-6 * torch.randn(hidden_size, n_class, requires_grad=True)]\n",
    "bs = [torch.zeros(hidden_size, requires_grad=True),\n",
    "      torch.zeros(n_class, requires_grad=True)]\n",
    "\n",
    "_ = compute_logs(ws, bs, reg_param, verbose=True)\n",
    "\n",
    "\n",
    "ws, bs = sgd_one_pass(ws, bs, X_train, y_train, reg_param, learning_rate, verbose=True)\n",
    "_ = compute_logs(ws, bs, reg_param, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.083, Test Loss = 2.303, Test Accuracy = 0.081\n",
      "1.46107600713891\n",
      "1.9903788106504632\n",
      "2.1612076340990174\n",
      "1.9793689601488735\n",
      "1.7811635875949923\n",
      "1.5341314154628456\n",
      "1.4288282150399647\n",
      "1.412291846771766\n",
      "1.4106128901755381\n",
      "1.1217416641903128\n",
      "1.2703717094377363\n",
      "1.1799129702774596\n",
      "1.3621871539763537\n",
      "1.6740801074301304\n",
      "1.4542208034664188\n",
      "1.1532732592158481\n",
      "1.0485062337958628\n",
      "1.2559974061789503\n",
      "1.2824544304436545\n",
      "1.3945337291726343\n",
      "1.4107607037666101\n",
      "1.3300449729007322\n",
      "0.9975905290909645\n",
      "0.8951120629321635\n",
      "1.0454754343215547\n",
      "1.1647457756272408\n",
      "1.4036739032697207\n",
      "1.0555314466596313\n",
      "1.1789548197238717\n",
      "0.9281729026506668\n",
      "1.3315724068343913\n",
      "1.5850403038775536\n",
      "1.9947450036530174\n",
      "1.8620281309683102\n",
      "1.7296919596206553\n",
      "1.4583310664808136\n",
      "1.3468045906955213\n",
      "1.2060831757322303\n",
      "1.4546425622405261\n",
      "1.5589335158620128\n",
      "1.7397043393621117\n",
      "1.7013752774986235\n",
      "3.0924652363484966\n",
      "2.476016932195362\n",
      "2.1601350411275555\n",
      "2.4111813762807186\n",
      "2.339921457806841\n",
      "2.102219867115858\n",
      "2.4719179254424244\n",
      "2.150868589662649\n",
      "1.7561205382123706\n",
      "1.9294680310044408\n",
      "2.150975084080452\n",
      "2.7943645596333724\n",
      "2.883261322319477\n",
      "2.4629320557790577\n",
      "2.545210042577001\n",
      "2.3635181545705\n",
      "1.7437778179350607\n",
      "1.2638710950583811\n",
      "1.3131687119599011\n",
      "2.1009874078271196\n",
      "2.2185395290492287\n",
      "1.604422349191954\n",
      "2.308956091799301\n",
      "2.4592823300571363\n",
      "2.5758821191424004\n",
      "2.1162605321879187\n",
      "2.5574454924476377\n",
      "2.6318039339728094\n",
      "2.6172578215363824\n",
      "2.7741527894550178\n",
      "Train Loss = 2.745, Train Accuracy = 0.608, Test Loss = 2.939, Test Accuracy = 0.599\n"
     ]
    }
   ],
   "source": [
    "# We find that 1e-2 is a good candidate for the divergent learning rate. We show this by running the code with 2*1e-2\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(1)\n",
    "reg_param = 0.0\n",
    "\n",
    "learning_rate = 2e-2\n",
    "\n",
    "hidden_size = 16 # Specifying hidden layer size as required by the assignment\n",
    "ws = [1e-6 * torch.randn(784, hidden_size, requires_grad=True),\n",
    "      1e-6 * torch.randn(hidden_size, n_class, requires_grad=True)]\n",
    "bs = [torch.zeros(hidden_size, requires_grad=True),\n",
    "      torch.zeros(n_class, requires_grad=True)]\n",
    "\n",
    "_ = compute_logs(ws, bs, reg_param, verbose=True)\n",
    "\n",
    "\n",
    "ws, bs = sgd_one_pass(ws, bs, X_train, y_train, reg_param, learning_rate, verbose=True)\n",
    "_ = compute_logs(ws, bs, reg_param, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the loss diverges with 2e-2. So 1e-2 is a good candidate for the divergent learning rate ($\\eta^\\star$). We will use 5e-3 as the learning rate ($\\eta^\\star/2$)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train the model for 120 passes over the training data for h=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "divergent_learning_rate = 5e-3\n",
    "\n",
    "def train_model(learning_rate=divergent_learning_rate, hidden_size=16):\n",
    "\n",
    "      logs = []\n",
    "\n",
    "      ws = [1e-6 * torch.randn(784, hidden_size, requires_grad=True),\n",
    "            1e-6 * torch.randn(hidden_size, n_class, requires_grad=True)]\n",
    "      bs = [torch.zeros(hidden_size, requires_grad=True),\n",
    "            torch.zeros(n_class, requires_grad=True)]\n",
    "      logs.append(compute_logs(ws, bs, reg_param, verbose=True))\n",
    "\n",
    "      for j in range(120):\n",
    "            ws, bs = sgd_one_pass(ws, bs, X_train, y_train, reg_param, learning_rate, verbose=False)\n",
    "            logs.append(compute_logs(ws, bs, reg_param, verbose=False))\n",
    "\n",
    "      logs = np.asarray(logs)\n",
    "      logs = np.hstack((np.ones((logs.shape[0], 1))*hidden_size, logs))\n",
    "\n",
    "      return logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.113, Test Loss = 2.303, Test Accuracy = 0.110\n"
     ]
    }
   ],
   "source": [
    "df_cols = ['hidden_size', 'train_loss', 'train_accuracy', 'test_loss', 'test_accuracy']\n",
    "results_16 = pd.DataFrame(columns=df_cols, data=train_model())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Repeat for different values of hidden layer size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 h=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.143, Test Loss = 2.303, Test Accuracy = 0.144\n"
     ]
    }
   ],
   "source": [
    "results_8 = pd.DataFrame(columns=df_cols, data=train_model(hidden_size=8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 h=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.114, Test Loss = 2.303, Test Accuracy = 0.112\n"
     ]
    }
   ],
   "source": [
    "results_32  = pd.DataFrame(columns=df_cols, data=train_model(hidden_size=32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 h=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.137, Test Loss = 2.303, Test Accuracy = 0.135\n"
     ]
    }
   ],
   "source": [
    "results_128 = pd.DataFrame(columns=df_cols, data=train_model(hidden_size=128))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 h=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss = 2.303, Train Accuracy = 0.079, Test Loss = 2.303, Test Accuracy = 0.071\n"
     ]
    }
   ],
   "source": [
    "results_512 = pd.DataFrame(columns=df_cols, data=train_model(hidden_size=512))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Assignment Deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending results to a single dataframe\n",
    "results = pd.concat([results_16, results_8, results_32, results_128, results_512], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find first occurernce of train_accuracy = 1.0 for each hidden size\n",
    "results['iter'] = results.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Make 4 plots, one each for the train loss, train accuracy, test loss and test accuracy over the course of training (i.e., the metric on the y-axis and number of effective passes on the x-axis). Plot all 4 lines, one for each value of h on the same plot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2. When the training accuracy is 100%, the model is said to interpolate the training data. What is the smallest width at which we observe perfect interpolation of the training data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.3. As we vary the width of the network, at which training epoch do we observe perfect interpolation of the data? That is, make a plot with h on the x-axis and number of passes over the data required for interpolation on the y axis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data598",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86858d5f84902b050d54a6bd9c0fb878f86a1dbd7a1ae5d42a558ee921f88707"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
